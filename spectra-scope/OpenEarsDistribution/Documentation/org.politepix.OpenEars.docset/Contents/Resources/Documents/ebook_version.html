<html style="height: 100%;"><header><style>.nobreak {page-break-after: always;page-break-inside: avoid;}</style> <link rel="stylesheet" media="screen, projection" href="file:///Users/me/Documents/MultiEars/BuildSystem/pdf.css" /></header><body style="height: 100%;"><div class="nobreak"><center><img src="file:///Users/me/Documents/MultiEars/BuildSystem/wheel.png"><h1>OpenEars 1.5.2 Manual</h1><h3>Written by Halle Winkler, published by Politepix</h3><h3>Tuesday, September 10, 2013</h3></center></div></body></html>
<html style="height: 100%;"><header><style>.nobreak {page-break-after: always;page-break-inside: avoid;} pre { overflow-x: auto; white-space: pre-wrap; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word; }</style> <link rel="stylesheet" media="screen, projection" href="file:///Users/me/Documents/MultiEars/BuildSystem/pdf.css" /></header><body style="height: 100%;"> <div class="nobreak"><div class="header"> <div class="headertitle"><div class="title"><h1>Introduction and Installation </h1></div></div></div><!--header--> <div class="contents"> <div class="textblock"><h1><a class="anchor" id="intro_sec"></a> Introduction</h1> <p>OpenEars is an shared-source iOS framework for iPhone voice recognition and speech synthesis (TTS). It lets you easily implement round-trip English and Spanish language speech recognition and English text-to-speech on the iPhone, iPod and iPad and uses the open source CMU Pocketsphinx, CMU Flite, and CMUCLMTK libraries, and it is free to use in an iPhone, iPad or iPod app (Spanish text-to-speech is possible on the OpenEars Platform but requires using <a href="http://www.politepix.com/neatspeech">NeatSpeech</a> since there isn't a Spanish voice for Flite). It is the most popular offline framework for speech recognition and speech synthesis on iOS and has been featured in development books such as O'Reilly's <em>Basic Sensors in iOS</em> by Alasdair Allan and <em>Cocos2d for iPhone 1 Game Development Cookbook</em> by Nathan Burba.</p> <p><a href="http://www.politepix.com/openearsplatform">The OpenEars Platform</a> is also a complete development platform for creating your speech recognition and text-to-speech apps including both the free OpenEars SDK documented on this page and a diverse <a href="http://www.politepix.com/openearsplatform">set of plugins</a> that can be added to OpenEars in order to extend and refine its default features: you can read more about the OpenEars platform <a href="http://www.politepix.com/openearsplatform">here</a>. This page is all about the free and shared-source OpenEars SDK, to please read on to learn more about it.</p> <p>Highly-accurate large-vocabulary recognition (that is, trying to recognize any word the user speaks out of many thousands of known words) is not yet a reality for local in-app processing on a small handheld device given the hardware limitations of the platform; even Siri does its large-vocabulary recognition on the server side. However, Pocketsphinx (the open source voice recognition engine that OpenEars uses) is capable of local recognition of vocabularies with hundreds of words depending on the environment and other factors, and performs very well with command-and-control language models in English and Spanish. The best part is that it uses no network connectivity because all processing occurs locally on the device.</p> <h5>The current version of OpenEars is 1.5.2.<a href="/wp-content/uploads/OpenEarsDistribution.tar.bz2">Download OpenEars</a> or read its <a href="http://www.politepix.com/openears/changelog/">changelog</a>.</h5> <h2><a class="anchor" id="step1"></a> Features of OpenEars</h2> <p>OpenEars can:</p> <ul> <li>Performs speech recognition and language model generation in English and in Spanish</li> <li>Performs text-to-speech in English and with the <a href="http://www.politepix.com/neatspeech">NeatSpeech</a> plugin, can also perform text-to-speech in Spanish</li> <li>Listen continuously for speech on a background thread, while suspending or resuming speech processing on demand, all while using less than 4% CPU on average on an iPhone 4 (decoding speech, text-to-speech, updating the UI and other intermittent functions use more CPU),</li> <li>Use any of 9 voices for speech, including male and female voices with a range of speed/quality level, and switch between them on the fly,</li> <li>Change the pitch, speed and variance of any text-to-speech voice,</li> <li>Know whether headphones are plugged in and continue voice recognition during text-to-speech only when they are plugged in,</li> <li>Support bluetooth audio devices (experimental),</li> <li>Dispatch information to any part of your app about the results of speech recognition and speech, or changes in the state of the audio session (such as an incoming phone call or headphones being plugged in),</li> <li>Deliver level metering for both speech input and speech output so you can design visual feedback for both states.</li> <li>Support JSGF grammars,</li> <li>Dynamically generate new ARPA language models in-app based on input from an NSArray of NSStrings,</li> <li>Switch between ARPA language models or JSGF grammars on the fly,</li> <li>Get n-best lists with scoring,</li> <li>Test existing recordings,</li> <li>Be easily interacted with via standard and simple Objective-C methods,</li> <li>Control all audio functions with text-to-speech and speech recognition in memory instead of writing audio files to disk and then reading them,</li> <li>Drive speech recognition with a low-latency Audio Unit driver for highest responsiveness,</li> <li>Be installed in a Cocoa-standard fashion using an easy-peasy already-compiled framework.</li> <li>In addition to its various new features and faster recognition/text-to-speech responsiveness, OpenEars now has improved recognition accuracy.</li> <li>OpenEars is free to use in an iPhone or iPad app.</li> </ul> <dl class="section warning"><dt>Warning</dt><dd>Before using OpenEars, please note it has to use a different audio driver on the Simulator that is less accurate, so it is always necessary to evaluate accuracy on a real device. Please don't submit support requests for accuracy issues with the Simulator.</dd></dl> <h1><a class="anchor" id="install_sec"></a> Installation</h1> <p>To use OpenEars:</p> <ul> <li><a href="/wp-content/uploads/OpenEarsDistribution.tar.bz2">Download the distribution</a> and unpack it.</li> </ul> <ul> <li>Create your own app, and add the iOS frameworks AudioToolbox and AVFoundation to it.</li> </ul> <ul> <li>Inside your downloaded distribution there is a folder called "Frameworks". Drag the "Frameworks" folder into your app project in Xcode.</li> </ul> <p>OK, now that you've finished laying the groundwork, you have to...wait, that's everything. You're ready to start using OpenEars. Give the sample app a spin to try out the features (the sample app uses ARC so you'll need a recent Xcode version) and then visit the <a href="http://www.politepix.com/openears/tutorial">Politepix interactive tutorial generator</a> for a customized tutorial showing you exactly what code to add to your app for all of the different functionality of OpenEars.</p> <p>If the steps on this page didn't work for you, you can get <a href="http://www.politepix.com/forums/openears">free support at the forums</a>, read the <a href="http://www.politepix.com/openears/support">FAQ</a>, brush up on the <a href="http://www.politepix.com/openears/#Basic_concepts">documentation</a>, or open a <a href="http://www.politepix.com/shop/openears-support-incident/">private email support incident at the Politepix shop</a>. If you'd like to read the documentation, simply read onward.</p> <h1><a class="anchor" id="concept_sec"></a> Basic concepts</h1> <p>There are a few basic concepts to understand about voice recognition and OpenEars that will make it easiest to create an app.</p> <ul> <li>Local or offline speech recognition versus server-based or online speech recognition: most speech recognition on the iPhone, iPod and iPad is done by streaming the speech audio to servers. OpenEars works by doing the recognition inside the device, entirely offline without using the network. This saves bandwidth and results in faster response, but since a server is much more powerful than a phone it means that we have to work with much smaller vocabularies to get accurate recognition.</li> </ul> <ul> <li>Language Models. The language model is the vocabulary that you want OpenEars to understand, in a format that its speech recognition engine can understand. The smaller and better-adapted to your users' real usage cases the language model is, the better the accuracy. An ideal language model for <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a> has fewer than 200 words.</li> <li>The parts of OpenEars. OpenEars has a simple, flexible and very powerful architecture. </li> </ul> <p><a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a> recognizes speech using a language model that was dynamically created by <a class="el" href="interface_language_model_generator.html" title="The class that generates the vocabulary the PocketsphinxController is able to understand.">LanguageModelGenerator</a>. <a class="el" href="interface_flite_controller.html" title="The class that controls speech synthesis (TTS) in OpenEars.">FliteController</a> creates synthesized speech (TTS). And <a class="el" href="interface_open_ears_events_observer.html" title="OpenEarsEventsObserver provides a large set of delegate methods that allow you to receive information...">OpenEarsEventsObserver</a> dispatches messages about every feature of OpenEars (what speech was understood by the engine, whether synthesized speech is in progress, if there was an audio interruption) to any part of your app. </p> </div></div><!-- contents --></div> <div class="nobreak"><div class="header"> <div class="summary"> <a href="class_acoustic_model-members.html"></a> </div> <div class="headertitle"><div class="title"><h1>AcousticModel Class Reference</h1></div></div></div><!--header--> <div class="contents"> <a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2> <div class="textblock"><p>Convenience class for accessing the acoustic model bundles. All this does is allow you to reference your chosen model by including this header in your class and then letting you call [<a class="el" href="interface_acoustic_model.html" title="Convenience class for accessing the acoustic model bundles. All this does is allow you to reference y...">AcousticModel</a> pathToModel:"AcousticModelEnglish"] or [AcousticModel pathToModel:@"AcousticModelSpanish"] in any of the methods which ask for a path to an acoustic model. </p> </div><h2 class="groupheader">Method Documentation</h2> <a class="anchor" id="ae7e0c41ef86d6540cf456988216718ff"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">+ (NSString *) pathToModel: </td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>acousticModelBundleName</em></td> <td></td> </tr> </table> </div><div class="memdoc"> <p>Reference the path to any acoustic model bundle you've dragged into your project (such as AcousticModelSpanish.bundle or AcousticModelEnglish.bundle) by calling this class method like [<a class="el" href="interface_acoustic_model.html" title="Convenience class for accessing the acoustic model bundles. All this does is allow you to reference y...">AcousticModel</a> pathToModel:"AcousticModelEnglish"] after importing this class. </p> </div> </div> </div><!-- contents --></div> <div class="nobreak"><div class="header"> <div class="summary"> <a href="class_flite_controller-members.html"></a> </div> <div class="headertitle"><div class="title"><h1>FliteController Class Reference</h1></div></div></div><!--header--> <div class="contents"> <a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2> <div class="textblock"><p>The class that controls speech synthesis (TTS) in OpenEars. </p> <h2>Usage examples</h2> <blockquote class="doxtable"> <p>Preparing to use the class:</p> <p></p> </blockquote> <p>To use FliteController, you need to have at least one Flite voice added to your project. When you added the "framework" folder of OpenEars to your app, you already imported a voice called Slt, so these instructions will use the Slt voice. You can get eight more free voices in OpenEarsExtras, available at <a href="https://bitbucket.org/Politepix/openearsextras">https://bitbucket.org/Politepix/openearsextras</a></p> <blockquote class="doxtable"> <p>What to add to your header:</p> <p></p> </blockquote> Add the following lines to your header (the .h file). Under the imports at the very top: <pre> #import &lt;Slt/Slt.h&gt; #import &lt;OpenEars/FliteController.h&gt; </pre> In the middle part where instance variables go: <pre> FliteController *fliteController; Slt *slt; </pre> In the bottom part where class properties go: <pre> @property (strong, nonatomic) FliteController *fliteController; @property (strong, nonatomic) Slt *slt; </pre> <blockquote class="doxtable"> <p>What to add to your implementation:</p> <p></p> </blockquote> Add the following to your implementation (the .m file): Under the @implementation keyword at the top: <pre> @synthesize fliteController; @synthesize slt; </pre> Among the other methods of the class, add these lazy accessor methods for confident memory management of the object: <pre> - (FliteController *)fliteController { if (fliteController == nil) { fliteController = [[FliteController alloc] init]; } return fliteController; } - (Slt *)slt { if (slt == nil) { slt = [[Slt alloc] init]; } return slt; } </pre> <blockquote class="doxtable"> <p>How to use the class methods:</p> <p></p> </blockquote> In the method where you want to call speech (to test this out, add it to your viewDidLoad method), add the following method call: <pre> [self.fliteController say:@"A short statement" withVoice:self.slt]; </pre> <dl class="section warning"><dt>Warning</dt><dd>There can only be one <a class="el" href="interface_flite_controller.html" title="The class that controls speech synthesis (TTS) in OpenEars.">FliteController</a> instance in your app at any given moment. </dd></dl> </div><h2 class="groupheader">Method Documentation</h2> <a class="anchor" id="a2e6655d69d560f5a71fbfcd531765ddc"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">- (void) say: </td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>statement</em></td> </tr> <tr> <td class="paramkey">withVoice:</td> <td></td> <td class="paramtype">(FliteVoice *)&#160;</td> <td class="paramname"><em>voiceToUse</em>&#160;</td> </tr> <tr> <td></td> <td></td> <td></td><td></td> </tr> </table> </div><div class="memdoc"> <p>This takes an NSString which is the word or phrase you want to say, and the FliteVoice to use to say the phrase. Usage Example: </p> <div class="fragment"><div class="line">[<span class="keyword">self</span>.fliteController say:<span class="stringliteral">@&quot;Say it, don&#39;t spray it.&quot;</span> withVoice:<span class="keyword">self</span>.slt];</div> </div><!-- fragment --><p> There are a total of nine FliteVoices available for use with OpenEars. The Slt voice is the most popular one and it ships with OpenEars. The other eight voices can be downloaded as part of the OpenEarsExtras package available at the URL <a href="http://bitbucket.org/Politepix/openearsextras">http://bitbucket.org/Politepix/openearsextras</a>. To use them, just drag the desired downloaded voice's framework into your app, import its header at the top of your calling class (e.g. import &lt;Slt/Slt.h&gt; or import &lt;Rms/Rms.h&gt;) and instantiate it as you would any other object, then passing the instantiated voice to this method. </p> </div> </div> <a class="anchor" id="ac497346e7c5338f443a776df6a2f66c2"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">- (Float32) fliteOutputLevel </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </div><div class="memdoc"> <p>A read-only attribute that tells you the volume level of synthesized speech in progress. This is a UI hook. You can't read it on the main thread. </p> </div> </div> <h2 class="groupheader">Property Documentation</h2> <a class="anchor" id="aaa307a1b50a18efb59d728e73fe032d4"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (float) duration_stretch</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>duration_stretch changes the speed of the voice. It is on a scale of 0.0-2.0 where 1.0 is the default. </p> </div> </div> <a class="anchor" id="a43e493842c33d7b487f4b61d749b0e34"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (float) target_mean</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>target_mean changes the pitch of the voice. It is on a scale of 0.0-2.0 where 1.0 is the default. </p> </div> </div> <a class="anchor" id="ad57f5befea71888c456ca54dfb41fc12"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (float) target_stddev</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>target_stddev changes convolution of the voice. It is on a scale of 0.0-2.0 where 1.0 is the default. </p> </div> </div> <a class="anchor" id="a1d49cd8cd10333f568c29527ad11d1e1"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (BOOL) userCanInterruptSpeech</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Set userCanInterruptSpeech to TRUE in order to let new incoming human speech cut off synthesized speech in progress. </p> </div> </div> <a class="anchor" id="a649534bf214e2dbe47f9d6ab2df6a258"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (BOOL) noAudioSessionOverrides</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Set noAudioSessionOverrides to TRUE in order to run Flite without the OpenEars AudioSessionManager (useful if you aren't using <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a> and you want to set your own audiosession behavior or have none but the defaults). This can't be used in combination with <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a>, it is only for apps which used <a class="el" href="interface_flite_controller.html" title="The class that controls speech synthesis (TTS) in OpenEars.">FliteController</a> exclusively. This BOOL is only picked up once per instantiation of <a class="el" href="interface_flite_controller.html" title="The class that controls speech synthesis (TTS) in OpenEars.">FliteController</a> so if you want to switch back and forth it is necessary to release your <a class="el" href="interface_flite_controller.html" title="The class that controls speech synthesis (TTS) in OpenEars.">FliteController</a> and create a new <a class="el" href="interface_flite_controller.html" title="The class that controls speech synthesis (TTS) in OpenEars.">FliteController</a> with the new noAudioSessionOverrides setting. </p> </div> </div> </div><!-- contents --></div> <div class="nobreak"><div class="header"> <div class="summary"> <a href="class_language_model_generator-members.html"></a> </div> <div class="headertitle"><div class="title"><h1>LanguageModelGenerator Class Reference</h1></div></div></div><!--header--> <div class="contents"> <a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2> <div class="textblock"><p>The class that generates the vocabulary the <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a> is able to understand. </p> <h2>Usage examples</h2> <blockquote class="doxtable"> <p>What to add to your implementation:</p> <p></p> </blockquote> Add the following to your implementation (the .m file): Under the @implementation keyword at the top: <pre> #import &lt;OpenEars/LanguageModelGenerator.h&gt; </pre> Wherever you need to instantiate the language model generator, do it as follows: <pre> LanguageModelGenerator *lmGenerator = [[LanguageModelGenerator alloc] init]; </pre> <blockquote class="doxtable"> <p>How to use the class methods:</p> <p></p> </blockquote> In offline speech recognition, you define the vocabulary that you want your app to be able to recognize. A good vocabulary size for an offline speech recognition app on the iPhone, iPod or iPad is between 3 and 300 words. <p> In the method where you want to create your language model (for instance your viewDidLoad method), add the following method call (replacing the placeholders like "WORD" and "A PHRASE" with actual words and phrases you want to be able to recognize):<p> <pre> NSArray *words = [NSArray arrayWithObjects:@"WORD", @"STATEMENT", @"OTHER WORD", @"A PHRASE", nil]; NSString *name = @"NameIWantForMyLanguageModelFiles"; NSError *err = [lmGenerator generateLanguageModelFromArray:words withFilesNamed:name forAcousticModelAtPath:[AcousticModel pathToModel:@"AcousticModelEnglish"]]; // Change "AcousticModelEnglish" to "AcousticModelSpanish" to create a Spanish language model instead of an English one. NSDictionary *languageGeneratorResults = nil; NSString *lmPath = nil; NSString *dicPath = nil; if([err code] == noErr) { languageGeneratorResults = [err userInfo]; lmPath = [languageGeneratorResults objectForKey:@"LMPath"]; dicPath = [languageGeneratorResults objectForKey:@"DictionaryPath"]; } else { NSLog(@"Error: %@",[err localizedDescription]); } </pre> If you are using the default English-language or Spanish-language model generation, it is a requirement to enter your words and phrases in all capital letters, since the model is generated against a dictionary in which the entries are capitalized (meaning that if the words in the array aren't capitalized, they will not match the dictionary and you will not have the widest variety of pronunciations understood for the word you are using). If you need to create a fixed language model ahead of time instead of creating it dynamically in your app, just use this method (or generateLanguageModelFromTextFile:withFilesNamed:) to submit your full language model using the Simulator and then use the <a href="http://www.politepix.com/2011/05/13/open-the-simulator-sandbox-folder-of-the-app-you-just-built-and-ran/">Simulator documents folder script</a> to get the language model and dictionary file out of the documents folder and add it to your app bundle, referencing it from there. </div><h2 class="groupheader">Method Documentation</h2> <a class="anchor" id="a2484802cfeb071e8e79b9297829f7ad5"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">- (NSError *) generateLanguageModelFromArray: </td> <td></td> <td class="paramtype">(NSArray *)&#160;</td> <td class="paramname"><em>languageModelArray</em></td> </tr> <tr> <td class="paramkey">withFilesNamed:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>fileName</em></td> </tr> <tr> <td class="paramkey">forAcousticModelAtPath:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>acousticModelPath</em>&#160;</td> </tr> <tr> <td></td> <td></td> <td></td><td></td> </tr> </table> </div><div class="memdoc"> <p>Generate a language model from an array of NSStrings which are the words and phrases you want <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a> or PocketsphinxController+RapidEars to understand, using your chosen acoustic model. Putting a phrase in as a string makes it somewhat more probable that the phrase will be recognized as a phrase when spoken. fileName is the way you want the output files to be named, for instance if you enter "MyDynamicLanguageModel" you will receive files output to your Caches directory titled MyDynamicLanguageModel.dic, MyDynamicLanguageModel.arpa, and MyDynamicLanguageModel.DMP. The error that this method returns contains the paths to the files that were created in a successful generation effort in its userInfo when NSError == noErr. The words and phrases in languageModelArray must be written with capital letters exclusively, for instance "word" must appear in the array as "WORD". </p> </div> </div> <a class="anchor" id="a1ccc2a5c5e1c1f0e8423640bf19435c5"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">- (NSError *) generateLanguageModelFromTextFile: </td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>pathToTextFile</em></td> </tr> <tr> <td class="paramkey">withFilesNamed:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>fileName</em></td> </tr> <tr> <td class="paramkey">forAcousticModelAtPath:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>acousticModelPath</em>&#160;</td> </tr> <tr> <td></td> <td></td> <td></td><td></td> </tr> </table> </div><div class="memdoc"> <p>Generate a language model from a text file containing words and phrases you want <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a> to understand, using your chosen acoustic model. The file should be formatted with every word or contiguous phrase on its own line with a line break afterwards. Putting a phrase in on its own line makes it somewhat more probable that the phrase will be recognized as a phrase when spoken. Give the correct full path to the text file as a string. fileName is the way you want the output files to be named, for instance if you enter "MyDynamicLanguageModel" you will receive files output to your Caches directory titled MyDynamicLanguageModel.dic, MyDynamicLanguageModel.arpa, and MyDynamicLanguageModel.DMP. The error that this method returns contains the paths to the files that were created in a successful generation effort in its userInfo when NSError == noErr. The words and phrases in languageModelArray must be written with capital letters exclusively, for instance "word" must appear in the array as "WORD". </p> </div> </div> <h2 class="groupheader">Property Documentation</h2> <a class="anchor" id="a3eaf11f4d03cd3a0a1974cb1f08b14c5"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (BOOL) verboseLanguageModelGenerator</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Set this to TRUE to get verbose output </p> </div> </div> <a class="anchor" id="adc19427601daf0c706901fca41b25fe0"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (BOOL) useFallbackMethod</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Advanced: if you are using your own acoustic model or an custom dictionary contained within an acoustic model and these don't use the same phonemes as the English or Spanish acoustic models, you will need to set useFallbackMethod to FALSE so that no attempt is made to use the English or Spanish fallback method for finding pronunciations of words which don't appear in the custom acoustic model's phonetic dictionary. </p> </div> </div> </div><!-- contents --></div> <div class="nobreak"><div class="header"> <div class="summary"> <a href="class_open_ears_events_observer-members.html"></a> </div> <div class="headertitle"><div class="title"><h1>OpenEarsEventsObserver Class Reference</h1></div></div></div><!--header--> <div class="contents"> <a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2> <div class="textblock"><p><a class="el" href="interface_open_ears_events_observer.html" title="OpenEarsEventsObserver provides a large set of delegate methods that allow you to receive information...">OpenEarsEventsObserver</a> provides a large set of delegate methods that allow you to receive information about the events in OpenEars from anywhere in your app. You can create as many OpenEarsEventsObservers as you need and receive information using them simultaneously. All of the documentation for the use of <a class="el" href="interface_open_ears_events_observer.html" title="OpenEarsEventsObserver provides a large set of delegate methods that allow you to receive information...">OpenEarsEventsObserver</a> is found in the section <a class="el" href="protocol_open_ears_events_observer_delegate-p.html" title="OpenEarsEventsObserver provides a large set of delegate methods that allow you to receive information...">OpenEarsEventsObserverDelegate</a>. </p> </div><h2 class="groupheader">Property Documentation</h2> <a class="anchor" id="a150a60d2b22ec462569aff76787047fe"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (id&lt; <a class="el" href="protocol_open_ears_events_observer_delegate-p.html">OpenEarsEventsObserverDelegate</a> &gt;) delegate</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">atomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>To use the <a class="el" href="protocol_open_ears_events_observer_delegate-p.html" title="OpenEarsEventsObserver provides a large set of delegate methods that allow you to receive information...">OpenEarsEventsObserverDelegate</a> methods, assign this delegate to the class hosting <a class="el" href="interface_open_ears_events_observer.html" title="OpenEarsEventsObserver provides a large set of delegate methods that allow you to receive information...">OpenEarsEventsObserver</a> and then use the delegate methods documented under <a class="el" href="protocol_open_ears_events_observer_delegate-p.html" title="OpenEarsEventsObserver provides a large set of delegate methods that allow you to receive information...">OpenEarsEventsObserverDelegate</a>. There is a complete example of how to do this explained under the <a class="el" href="protocol_open_ears_events_observer_delegate-p.html" title="OpenEarsEventsObserver provides a large set of delegate methods that allow you to receive information...">OpenEarsEventsObserverDelegate</a> documentation. </p> </div> </div> </div><!-- contents --></div> <div class="nobreak"><div class="header"> <div class="summary"> <a href="class_open_ears_logging-members.html"></a> </div> <div class="headertitle"><div class="title"><h1>OpenEarsLogging Class Reference</h1></div></div></div><!--header--> <div class="contents"> <a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2> <div class="textblock"><p>A singleton which turns logging on or off for the entire framework. The type of logging is related to overall framework functionality such as the audio session and timing operations. Please turn <a class="el" href="interface_open_ears_logging.html" title="A singleton which turns logging on or off for the entire framework. The type of logging is related to...">OpenEarsLogging</a> on for any issue you encounter. It will probably show the problem, but if not you can show the log on the forum and get help. </p> <dl class="section warning"><dt>Warning</dt><dd>The individual classes such as <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a> and <a class="el" href="interface_language_model_generator.html" title="The class that generates the vocabulary the PocketsphinxController is able to understand.">LanguageModelGenerator</a> have their own verbose flags which are separate from <a class="el" href="interface_open_ears_logging.html" title="A singleton which turns logging on or off for the entire framework. The type of logging is related to...">OpenEarsLogging</a>. </dd></dl> </div><h2 class="groupheader">Method Documentation</h2> <a class="anchor" id="abc1654d2825bbf04e4e8e8f4f0ad6e18"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">+ (id) startOpenEarsLogging </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </div><div class="memdoc"> <p>This just turns on logging. If you don't want logging in your session, don't send the startOpenEarsLogging message. </p> <blockquote class="doxtable"> <p>Example Usage:</p> <p></p> </blockquote> <p>Before implementation: </p> <div class="fragment"><div class="line"><span class="preprocessor">#import &lt;OpenEars/OpenEarsLogging.h&gt;</span>;</div> </div><!-- fragment --><p> In implementation: </p> <div class="fragment"><div class="line">[<a class="code" href="interface_open_ears_logging.html" title="A singleton which turns logging on or off for the entire framework. The type of logging is related to...">OpenEarsLogging</a> <a class="code" href="interface_open_ears_logging.html#abc1654d2825bbf04e4e8e8f4f0ad6e18" title="This just turns on logging. If you don&#39;t want logging in your session, don&#39;t send the startOpenEarsLo...">startOpenEarsLogging</a>];</div> </div><!-- fragment --> </div> </div> </div><!-- contents --></div> <div class="nobreak"><div class="header"> <div class="summary"> <a href="class_pocketsphinx_controller-members.html"></a> </div> <div class="headertitle"><div class="title"><h1>PocketsphinxController Class Reference</h1></div></div></div><!--header--> <div class="contents"> <a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2> <div class="textblock"><p>The class that controls local speech recognition in OpenEars. </p> <h2>Usage examples</h2> <blockquote class="doxtable"> <p>Preparing to use the class:</p> <p></p> </blockquote> <p>To use PocketsphinxController, you need a language model and a phonetic dictionary for it. These files define which words PocketsphinxController is capable of recognizing. They are created above by using LanguageModelGenerator. You also need an acoustic model. OpenEars ships with an English and a Spanish acoustic model.</p> <blockquote class="doxtable"> <p>What to add to your header:</p> <p></p> </blockquote> Add the following lines to your header (the .h file). Under the imports at the very top: <pre> #import &lt;OpenEars/PocketsphinxController.h&gt; #import &lt;OpenEars/AcousticModel.h&gt; </pre> In the middle part where instance variables go: <pre> PocketsphinxController *pocketsphinxController; </pre> In the bottom part where class properties go: <pre> @property (strong, nonatomic) PocketsphinxController *pocketsphinxController; </pre> <blockquote class="doxtable"> <p>What to add to your implementation:</p> <p></p> </blockquote> Add the following to your implementation (the .m file): Under the @implementation keyword at the top: <pre> @synthesize pocketsphinxController; </pre> Among the other methods of the class, add this lazy accessor method for confident memory management of the object: <pre> - (PocketsphinxController *)pocketsphinxController { if (pocketsphinxController == nil) { pocketsphinxController = [[PocketsphinxController alloc] init]; } return pocketsphinxController; } </pre> <blockquote class="doxtable"> <p>How to use the class methods:</p> <p></p> </blockquote> In the method where you want to recognize speech (to test this out, add it to your viewDidLoad method), add the following method call: <pre> [self.pocketsphinxController startListeningWithLanguageModelAtPath:lmPath dictionaryAtPath:dicPath acousticModelAtPath:[AcousticModel pathToModel:@"AcousticModelEnglish"] languageModelIsJSGF:NO]; // Change "AcousticModelEnglish" to "AcousticModelSpanish" to perform Spanish recognition instead of English. </pre> <dl class="section warning"><dt>Warning</dt><dd>There can only be one <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a> instance in your app. </dd></dl> </div><h2 class="groupheader">Method Documentation</h2> <a class="anchor" id="a5f2fb597c5b47fe2f8cb09d60601ff54"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">- (void) startListeningWithLanguageModelAtPath: </td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>languageModelPath</em></td> </tr> <tr> <td class="paramkey">dictionaryAtPath:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>dictionaryPath</em></td> </tr> <tr> <td class="paramkey">acousticModelAtPath:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>acousticModelPath</em></td> </tr> <tr> <td class="paramkey">languageModelIsJSGF:</td> <td></td> <td class="paramtype">(BOOL)&#160;</td> <td class="paramname"><em>languageModelIsJSGF</em>&#160;</td> </tr> <tr> <td></td> <td></td> <td></td><td></td> </tr> </table> </div><div class="memdoc"> <p>Start the speech recognition engine up. You provide the full paths to a language model and a dictionary file which are created using <a class="el" href="interface_language_model_generator.html" title="The class that generates the vocabulary the PocketsphinxController is able to understand.">LanguageModelGenerator</a> and the acoustic model you want to use (for instance [<a class="el" href="interface_acoustic_model.html" title="Convenience class for accessing the acoustic model bundles. All this does is allow you to reference y...">AcousticModel</a> pathToModel:"AcousticModelEnglish"]). </p> </div> </div> <a class="anchor" id="ab010e9f7f5f730ffb62eb38be19d0388"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">- (void) stopListening </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </div><div class="memdoc"> <p>Shut down the engine. You must do this before releasing a parent view controller that contains <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a>. </p> </div> </div> <a class="anchor" id="aeaa63998081a505eb2338ab816562892"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">- (void) suspendRecognition </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </div><div class="memdoc"> <p>Keep the engine going but stop listening to speech until resumeRecognition is called. Takes effect instantly. </p> </div> </div> <a class="anchor" id="a773129a910600f077a3c679ca3e9e5df"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">- (void) resumeRecognition </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </div><div class="memdoc"> <p>Resume listening for speech after suspendRecognition has been called. </p> </div> </div> <a class="anchor" id="adc692425dd239522865c3aa903a9c422"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">- (void) changeLanguageModelToFile: </td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>languageModelPathAsString</em></td> </tr> <tr> <td class="paramkey">withDictionary:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>dictionaryPathAsString</em>&#160;</td> </tr> <tr> <td></td> <td></td> <td></td><td></td> </tr> </table> </div><div class="memdoc"> <p>Change from one language model to another. This lets you change which words you are listening for depending on the context in your app. If you have already started the recognition loop and you want to switch to a different language model, you can use this and the model will be changed at the earliest opportunity. Will not have any effect unless recognition is already in progress. It isn't possible to change acoustic models in the middle of an already-started listening loop, just language model and dictionary. </p> </div> </div> <a class="anchor" id="ad573849f9caebd3ac39ddfbec9b944ad"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">- (Float32) pocketsphinxInputLevel </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </div><div class="memdoc"> <p>Gives the volume of the incoming speech. This is a UI hook. You can't read it on the main thread or it will block. </p> </div> </div> <a class="anchor" id="ad7635d1e4287145c1c631b61c632db6f"></a> <div class="memitem"> <div class="memproto"> <table class="memname"> <tr> <td class="memname">- (void) runRecognitionOnWavFileAtPath: </td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>wavPath</em></td> </tr> <tr> <td class="paramkey">usingLanguageModelAtPath:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>languageModelPath</em></td> </tr> <tr> <td class="paramkey">dictionaryAtPath:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>dictionaryPath</em></td> </tr> <tr> <td class="paramkey">acousticModelAtPath:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>acousticModelPath</em></td> </tr> <tr> <td class="paramkey">languageModelIsJSGF:</td> <td></td> <td class="paramtype">(BOOL)&#160;</td> <td class="paramname"><em>languageModelIsJSGF</em>&#160;</td> </tr> <tr> <td></td> <td></td> <td></td><td></td> </tr> </table> </div><div class="memdoc"> <p>You can use this to run recognition on an already-recorded WAV file for testing. The WAV file has to be 16-bit and 16000 samples per second. </p> </div> </div> <h2 class="groupheader">Property Documentation</h2> <a class="anchor" id="a4b041461b83ae9a95891e4df343288f5"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (float) secondsOfSilenceToDetect</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>This is how long <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a> should wait after speech ends to attempt to recognize speech. This defaults to .7 seconds. </p> </div> </div> <a class="anchor" id="a441a879be770c054c14e9211b695cc83"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (BOOL) returnNbest</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Advanced: set this to TRUE to receive n-best results. </p> </div> </div> <a class="anchor" id="a4acb3744552cd6278e71c3e26ab9e012"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (int) nBestNumber</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Advanced: the number of n-best results to return. This is a maximum number to return &ndash; if there are null hypotheses fewer than this number will be returned. </p> </div> </div> <a class="anchor" id="a2f3a25d874a131b0d20c55901ecf71e6"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (int) calibrationTime</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>How long to calibrate for. This can only be one of the values '1', '2', or '3'. Defaults to 1. </p> </div> </div> <a class="anchor" id="a8be278e1f934200ca3ef2e259b5fe87c"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (BOOL) verbosePocketSphinx</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Turn on verbose output. Do this any time you encounter an issue and any time you need to report an issue on the forums. </p> </div> </div> <a class="anchor" id="af948a6a704dc338b2f0c21b6bf987b9f"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (BOOL) returnNullHypotheses</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>By default, <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a> won't return a hypothesis if for some reason the hypothesis is null (this can happen if the perceived sound was just noise). If you need even empty hypotheses to be returned, you can set this to TRUE before starting <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a>. </p> </div> </div> <a class="anchor" id="abeaddf4fc43d1b716846bd754ca57cb0"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (NSString *) pathToTestFile</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">copy</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>By setting pathToTestFile to point to a recorded audio file you can run the main Pocketsphinx listening loop (not runRecognitionOnWavFileAtPath but the main loop invoked by using startListeningWithLanguageModelAtPath:) over a pre-recorded audio file instead of using it with live input. In contrast with using the method runRecognitionOnWavFileAtPath to receive a single recognition from a file, with this approach the audio file will have its buffers injected directly into the audio driver circular buffer for maximum fidelity to the goal of testing the entire codebase that is in use when doing a live recognition, including the whole driver, the calibration code, and the listening loop including all of its features. This is for creating tests for yourself and for sharing automatically replicable issue reports with Politepix. To use this, make an audio recording on the same device (i.e., if you are testing <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a> on an iPhone 5 with the internal microphone, make a recording on an iPhone 5 with the internal microphone, for instance using Apple's Voice Memos app) and then convert the resulting file to a 16-bit, 16000 sample rate, mono WAV file. You can do this with the output of Apple's Voice Memos app by taking the .m4a file that Voice Memos outputs and run it through this command in Terminal.app: "afconvert -f WAVE -d LEI16@16000 -c 1 ~/Desktop/Memo.m4a ~/Desktop/Memo.wav" Then add the WAV file to your app, and right before sending the call to startListeningWithLanguageModelAtPath, set this property pathToTestFile to the path to your audio file in your app as an NSString (e.g. [[NSBundle mainBundle] pathForResource:"Memo" ofType:@"wav"]). Note: when you record the audio file you will be using to test with, <b>always</b> make sure to have 5 seconds of silence at the beginning so there is enough time for calibration to be performed on your recording environment, since calibration is also part of the test. SmartCMN is disabled during testing so that the test gets the same results when run for different people. Please keep in mind that there are some settings in Pocketsphinx which may prevent a deterministic outcome from a recognition, meaning that you should expect a <b>similar</b> score over multiple runs of a test but you may not always see the <b>identical</b> score. For this reason and the fact that <a class="el" href="interface_pocketsphinx_controller.html" title="The class that controls local speech recognition in OpenEars.">PocketsphinxController</a> is asynchronous and results in real practice are delivered via uncoupled callback it has not been designed as a purely automated test, but as an observed practical test. If it were designed as a purely automated test it would be testing something other than the way PocketsphinxController/OpenEarsEventsObserver works in an app, which is designed for good speech implementations rather than tests. </p> </div> </div> <a class="anchor" id="ad67f3122b7ad297e03be888c5a204023"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (BOOL) audioSessionMixing</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">assign</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Set this to true in order to allow audio session mixing </p> </div> </div> <a class="anchor" id="a1e45e3aba2b0116c66ea8012ffec02dd"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (NSString *) audioMode</td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">read</span><span class="mlabel" style="display:none;">write</span><span class="mlabel" style="display:none;">nonatomic</span><span class="mlabel" style="display:none;">copy</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>If you are using 5.0 or greater, you can set audio modes for the audio session manager to use. This can be set to the following:</p> <p>"Default" to use kAudioSessionMode_Default = ‘dflt’, @"VoiceChat" to use kAudioSessionMode_VoiceChat = ‘vcct’, @"VideoRecording" kAudioSessionMode_VideoRecording = ‘vrcd’, @"Measurement" kAudioSessionMode_Measurement = ‘msmt’</p> <p>If you don't set it to anything, default will automatically be used. </p> </div> </div> </div><!-- contents --></div> <div class="nobreak"><div class="header"> <div class="summary"> <a href="protocol_open_ears_events_observer_delegate-p-members.html"></a> </div> <div class="headertitle"><div class="title"><h1>&lt;OpenEarsEventsObserverDelegate&gt; Protocol Reference</h1><span class="mlabels"><span class="mlabel" style="display:none;">abstract</span></span></div></div></div><!--header--> <div class="contents"> <a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2> <div class="textblock"><p><a class="el" href="interface_open_ears_events_observer.html" title="OpenEarsEventsObserver provides a large set of delegate methods that allow you to receive information...">OpenEarsEventsObserver</a> provides a large set of delegate methods that allow you to receive information about the events in OpenEars from anywhere in your app. You can create as many OpenEarsEventsObservers as you need and receive information using them simultaneously. </p> <h2>Usage examples</h2> <blockquote class="doxtable"> <p>What to add to your header:</p> <p></p> </blockquote> Add the following lines to your header (the .h file). Under the imports at the very top: <pre> #import &lt;OpenEars/OpenEarsEventsObserver.h&gt; </pre> at the @interface declaration, add the OpenEarsEventsObserverDelegate inheritance. An example of this for a view controller called ViewController would look like this: <pre> @interface ViewController : UIViewController &lt;OpenEarsEventsObserverDelegate&gt { </pre> In the middle part where instance variables go: <pre> OpenEarsEventsObserver *openEarsEventsObserver; </pre> In the bottom part where class properties go: <pre> @property (strong, nonatomic) OpenEarsEventsObserver *openEarsEventsObserver; </pre> <blockquote class="doxtable"> <p>What to add to your implementation:</p> <p></p> </blockquote> Add the following to your implementation (the .m file): Under the @implementation keyword at the top: <pre> @synthesize openEarsEventsObserver; </pre> Among the other methods of the class, add this lazy accessor method for confident memory management of the object: <pre> - (OpenEarsEventsObserver *)openEarsEventsObserver { if (openEarsEventsObserver == nil) { openEarsEventsObserver = [[OpenEarsEventsObserver alloc] init]; } return openEarsEventsObserver; } </pre> and then right before you start your first OpenEars functionality (for instance, right before your first self.fliteController say:withVoice: message or right before your first self.pocketsphinxController startListeningWithLanguageModelAtPath:dictionaryAtPath:languageModelIsJSGF: message) send this message: <pre> [self.openEarsEventsObserver setDelegate:self]; </pre> <blockquote class="doxtable"> <p>How to use the class methods:</p> <p></p> </blockquote> Add these delegate methods of OpenEarsEventsObserver to your class: <pre> - (void) pocketsphinxDidReceiveHypothesis:(NSString *)hypothesis recognitionScore:(NSString *)recognitionScore utteranceID:(NSString *)utteranceID { NSLog(@"The received hypothesis is %@ with a score of %@ and an ID of %@", hypothesis, recognitionScore, utteranceID); } - (void) pocketsphinxDidStartCalibration { NSLog(@"Pocketsphinx calibration has started."); } - (void) pocketsphinxDidCompleteCalibration { NSLog(@"Pocketsphinx calibration is complete."); } - (void) pocketsphinxDidStartListening { NSLog(@"Pocketsphinx is now listening."); } - (void) pocketsphinxDidDetectSpeech { NSLog(@"Pocketsphinx has detected speech."); } - (void) pocketsphinxDidDetectFinishedSpeech { NSLog(@"Pocketsphinx has detected a period of silence, concluding an utterance."); } - (void) pocketsphinxDidStopListening { NSLog(@"Pocketsphinx has stopped listening."); } - (void) pocketsphinxDidSuspendRecognition { NSLog(@"Pocketsphinx has suspended recognition."); } - (void) pocketsphinxDidResumeRecognition { NSLog(@"Pocketsphinx has resumed recognition."); } - (void) pocketsphinxDidChangeLanguageModelToFile:(NSString *)newLanguageModelPathAsString andDictionary:(NSString *)newDictionaryPathAsString { NSLog(@"Pocketsphinx is now using the following language model: \n%@ and the following dictionary: %@",newLanguageModelPathAsString,newDictionaryPathAsString); } - (void) pocketSphinxContinuousSetupDidFail { // This can let you know that something went wrong with the recognition loop startup. Turn on OPENEARSLOGGING to learn why. NSLog(@"Setting up the continuous recognition loop has failed for some reason, please turn on OpenEarsLogging to learn more."); } - (void) testRecognitionCompleted { NSLog(@"A test file that was submitted for recognition is now complete."); } </pre> </div><h2 class="groupheader">Method Documentation</h2> <a class="anchor" id="ae73cc578452747a361cac98a3674d664"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) audioSessionInterruptionDidBegin </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>There was an interruption. </p> </div> </div> <a class="anchor" id="a712976ff66be9adf04280f34cf3efab9"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) audioSessionInterruptionDidEnd </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>The interruption ended. </p> </div> </div> <a class="anchor" id="ac5b56d030491c6e27be5ca2b7080be93"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) audioInputDidBecomeUnavailable </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>The input became unavailable. </p> </div> </div> <a class="anchor" id="ae04927da6e93cf041530544b47edcdb1"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) audioInputDidBecomeAvailable </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>The input became available again. </p> </div> </div> <a class="anchor" id="a6ecb54845f3471a1745994c4f90d2f2b"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) audioRouteDidChangeToRoute: </td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>newRoute</em></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>The audio route changed. </p> </div> </div> <a class="anchor" id="adc5c225519fddc40552d0eb0a88aa2a2"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketsphinxDidStartCalibration </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Pocketsphinx isn't listening yet but it started calibration. </p> </div> </div> <a class="anchor" id="af96dcf8dee806bec948af2e03a6f96f2"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketsphinxDidCompleteCalibration </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Pocketsphinx isn't listening yet but calibration completed. </p> </div> </div> <a class="anchor" id="a1a7eecf0669637a1fea2b645bd0c607a"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketsphinxRecognitionLoopDidStart </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Pocketsphinx isn't listening yet but it has entered the main recognition loop. </p> </div> </div> <a class="anchor" id="aaf32ba3e0e5dc1d0f862edcf1e4a8c15"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketsphinxDidStartListening </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Pocketsphinx is now listening. </p> </div> </div> <a class="anchor" id="a1d61b59cc1ee03a95c387dcd2cf5355b"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketsphinxDidDetectSpeech </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Pocketsphinx heard speech and is about to process it. </p> </div> </div> <a class="anchor" id="a5935c0fd7d52b02e5b2c955449a7d8fe"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketsphinxDidDetectFinishedSpeech </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Pocketsphinx detected a second of silence indicating the end of an utterance </p> </div> </div> <a class="anchor" id="a5c3747a960cf21316f909619cfb4a2cb"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketsphinxDidReceiveHypothesis: </td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>hypothesis</em></td> </tr> <tr> <td class="paramkey">recognitionScore:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>recognitionScore</em></td> </tr> <tr> <td class="paramkey">utteranceID:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>utteranceID</em>&#160;</td> </tr> <tr> <td></td> <td></td> <td></td><td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Pocketsphinx has a hypothesis. </p> </div> </div> <a class="anchor" id="a62cd5c9caa23a2c20028f226884a0480"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketsphinxDidReceiveNBestHypothesisArray: </td> <td></td> <td class="paramtype">(NSArray *)&#160;</td> <td class="paramname"><em>hypothesisArray</em></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Pocketsphinx has an n-best hypothesis dictionary. </p> </div> </div> <a class="anchor" id="a9230f6b9e89aacd6f3f71f8794dc7be1"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketsphinxDidStopListening </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Pocketsphinx has exited the continuous listening loop. </p> </div> </div> <a class="anchor" id="a3aedb6ad9ec4b13cf4efd8be80edd9b9"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketsphinxDidSuspendRecognition </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Pocketsphinx has not exited the continuous listening loop but it will not attempt recognition. </p> </div> </div> <a class="anchor" id="a10f329c6b574be3f3a88fb91c711d615"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketsphinxDidResumeRecognition </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Pocketsphinx has not existed the continuous listening loop and it will now start attempting recognition again. </p> </div> </div> <a class="anchor" id="a2f0ad334ad365dc4819340394ceaea07"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketsphinxDidChangeLanguageModelToFile: </td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>newLanguageModelPathAsString</em></td> </tr> <tr> <td class="paramkey">andDictionary:</td> <td></td> <td class="paramtype">(NSString *)&#160;</td> <td class="paramname"><em>newDictionaryPathAsString</em>&#160;</td> </tr> <tr> <td></td> <td></td> <td></td><td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Pocketsphinx switched language models inline. </p> </div> </div> <a class="anchor" id="a51a806214b23b405b25a98691b5481cf"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) pocketSphinxContinuousSetupDidFail </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Some aspect of setting up the continuous loop failed, turn on <a class="el" href="interface_open_ears_logging.html" title="A singleton which turns logging on or off for the entire framework. The type of logging is related to...">OpenEarsLogging</a> for more info. </p> </div> </div> <a class="anchor" id="a3aca3725617ff3c8abfbd84962cefafa"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) testRecognitionCompleted </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Your test recognition run has completed. </p> </div> </div> <a class="anchor" id="a07384b08e2f02f99904c9d4caddae322"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) fliteDidStartSpeaking </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Flite started speaking. You probably don't have to do anything about this. </p> </div> </div> <a class="anchor" id="a9cb867a714d6bc48e0b621af2330fb97"></a> <div class="memitem"> <div class="memproto"> <table class="mlabels"> <tr> <td class="mlabels-left"> <table class="memname"> <tr> <td class="memname">- (void) fliteDidFinishSpeaking </td> <td></td> <td class="paramname"></td> <td></td> </tr> </table> </td> <td class="mlabels-right"> <span class="mlabels"><span class="mlabel" style="display:none;">optional</span></span> </td> </tr> </table> </div><div class="memdoc"> <p>Flite finished speaking. You probably don't have to do anything about this. </p> </div> </div> </div><!-- contents --></div> </body></header></html>
